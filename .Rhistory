updateSelectInput(session, inputId = "theMethod", label = NULL,
choices = list("Multiple Linear Regression"))
}
else if(input$theVariable == "sex")
{
updateSelectInput(session, inputId = "theMethod", label = NULL,
choices = list("Linear Discriminant Analysis","Logistic Regression"))
}
else if(input$theVariable == "youtube")
{
updateSelectInput(session, inputId = "theMethod", label = NULL,
choices = list("Multiple Linear Regression", "Ridge Regression", "LASSO"))
}
else if(input$theVariable == "sales")
{
updateSelectInput(session, inputId = "theMethod", label = NULL,
choices = list("Multiple Linear Regression", "Ridge Regression", "LASSO"))
}
else if(input$theVariable == "target")
{
updateSelectInput(session, inputId = "theMethod", label = NULL,
choices = list("Logistic Regression","Linear Discriminant Analysis"))
}
else if(input$theVariable == "trestbps")
{
updateSelectInput(session, inputId = "theMethod", label = NULL,
choices = list("Multiple Linear Regression"))
}
else
{
#print("test")
}
tracking$DT <- data.frame(
percentTraining = numeric(),
accuracyValue = numeric()
)
})
#Input: data set, the testingPercent (average .8), method used
#output: returns the percent accuracy of the model.
#percent <- calculateAccuracy(dataset, input$testingPercent, input$theMethod, predictor, predictionVariable)
#----calculateAccuracy()----
calculateAccuracy <- function(theDataSet, testingPercent, method, predictor, predictionVariable) #predictor replaces theDataSet$Species, preictionVariable is just 'variableString'
{
validation_index <- createDataPartition(y = predictor, p = testingPercent, list = FALSE) #p usually input$testingPercent
#dataset <- dataset(na.action=na.exclude)
validation <- theDataSet[-validation_index,]
trainingDataset <- theDataSet[validation_index,]
sapply(trainingDataset,class)
if(method == 'Linear Discriminant Analysis') {
fit.lda <- lda(eval(parse(text = paste(predictionVariable,'~.'))), data=trainingDataset, na.action="na.omit")
predictions <- predict(object = fit.lda, newdata = validation)
finalPredictions <- predictions$class
outputType <- "categorical"
}
else if(method == 'Multiple Linear Regression')
{
fit.lm <- lm(eval(parse(text = paste(predictionVariable, '~.'))), data = trainingDataset)
finalPredictions <- predict(fit.lm, validation)
outputType <- "continuous"
}
else if(method == 'Logistic Regression'){
fit.lr <- glm(eval(parse(text = paste(predictionVariable, '~.'))), data = trainingDataset, family = "binomial")
probabilities <- predict(fit.lr, validation, type = "response")
if(predictionVariable ==  "sex")
finalPredictions <- ifelse(probabilities < 0.5, "female", "male")
else if(predictionVariable == "target"){
finalPredictions <- ifelse(probabilities > 0.5, 1, 0) #1 unhealthy and 2 healthy
}
else
print("")
#fit.lr <- glm(target ~ ., data = trainingDataset, family = "binomial")
#probabilities <- predict(fit.lr, validation, type = "response")
#finalPredictions <- ifelse(probabilities > 0.5, "Unhealthy", "Healthy")
outputType <- "categorical"
}
else if(method == "Ridge Regression")
{
#x <- model.matrix( ~ ., trainingDataset)
x <- as.matrix(trainingDataset[, names(trainingDataset) != predictionVariable])
y <- as.matrix(trainingDataset[, predictionVariable])
fit.glm <- glmnet(x, y, family="gaussian", alpha=0, lambda=0.001)
finalPredictions <- predict(fit.glm, data.matrix(validation[, names(trainingDataset) != predictionVariable]), type = "response") #type used to = "link"
outputType <- "continuous"
}
else if(method == "LASSO")
{
# fit model
#print(theDataSet[,1:3])
x <- data.matrix(trainingDataset[, names(trainingDataset) != predictionVariable])
y <- data.matrix(trainingDataset[, predictionVariable])
fit.lars <- lars(x, y, type="lasso")
# select a step with a minimum error
best_step <- fit.lars$df[which.min(fit.lars$RSS)]
# make predictions
finalPredictions <- predict(fit.lars, data.matrix(validation[,names(trainingDataset) != predictionVariable]), s=best_step, type="fit")$fit
outputType <- "continuous"
}
else
{
}
#6 Make predictions
#Estimate accuracy of LDA on validation dataset
if(outputType == "categorical")
{
count <- 0
correct <- 0
for(word in finalPredictions)
{
count <- count + 1
if(word == eval(parse(text= paste('validation$',predictionVariable,'[',count,']'))))
correct <- correct + 1
}
percentCorrect <- correct / count
percentCorrect <- percentCorrect * 100
return(percentCorrect)
}
else #For continuous
{
count <- 0
MSE <- 0
for(number in finalPredictions)
{
count <- count + 1
MSE = MSE + ((number - eval(parse(text= paste('validation$',predictionVariable,'[',count,']'))))^2)
}
MSE <- MSE / count
return(MSE)
}
}
#----Ouput runTest 1 accuracy function----
observeEvent(input$runTest,{
#print('submit detected')
if(input$theDataSet == 'Iris'){
dataset <- iris
predictor <- iris$Species      #predictor is the variable that we are going to try to predict based off training data algorithm testing the validation algorithm
predictionVariable <- input$theVariable
}
else if(input$theDataSet == 'Marketing')
{
dataset <- read.csv("marketing.csv")
predictor <- dataset$sales
predictionVariable <- input$theVariable
}
else if(input$theDataSet == 'Palmer Penguins'){
dataset <- na.omit(penguins)
predictor <- dataset$species
predictionVariable <- input$theVariable
}
# else if(input$theDataSet == "House Data"){
#   #dataset <- read.csv("HouseTrain.csv")
#   dataset <- read.csv("Reduced_HouseTrain.csv")
#   predictor <- dataset$SalePrice
#   predictionVariable <- 'SalePrice'
# }
else if(input$theDataSet == "Heart Disease")
{
#https://www.youtube.com/watch?v=C4N3_XJJ-jU was important
#undid a lot of as.factors
dataset <- read.csv("HeartDiseaseData.csv")
#Cleaning
dataset[dataset == "?"] <- NA
dataset <- na.omit(dataset)
#dataset[dataset$sex == 0,]$sex <- "female"
#dataset[dataset$sex == 1,]$sex <- "male"
dataset$sex <- as.factor(dataset$sex)
dataset$cp <- as.factor(dataset$cp)
dataset$fbs <- as.factor(dataset$fbs)
dataset$exang <- as.factor(dataset$exang)
dataset$slope <- as.factor(dataset$slope)
# dataset$ca <- as.integer(dataset$ca)
# dataset$ca <- as.factor(dataset$ca)
dataset$thal <- as.integer(dataset$thal) # "thal" also had "?"s in it.
dataset$thal <- as.factor(dataset$thal)
## This next line replaces 0 and 1 with "Healthy" and "Unhealthy"
#dataset$target <- ifelse(test=dataset$target == 0, yes="Healthy", no="Unhealthy") #I might remove
dataset$target <- as.factor(dataset$target) # Now convert to a factor
predictor <- dataset$target
predictionVariable <- input$theVariable
}
else{
#print('ERROR')
}
percentCorrect <- calculateAccuracy(dataset, input$testingPercent, input$theMethod, predictor, predictionVariable)
percentCorrect <- signif(percentCorrect,4) #
if(input$theMethod == "Linear Discriminant Analysis" || input$theMethod == "Logistic Regression")
output$accuracyResult <- renderText({paste(percentCorrect,' ', 'Percent is the accuracy when the percent of training data is',isolate(input$testingPercent))})
else
output$accuracyResult <- renderText({paste(percentCorrect,' ', ' is the mean sum of squares',isolate(input$testingPercent))})
})
#Outputs the graph
#----OutputGraphFunction----
observeEvent(input$outputGraph, {
if(input$theDataSet == 'Iris'){
dataset <- na.omit(iris)
predictor <- iris$Species      #predictor is the variable that we are going to try to predict based off training data algorithm testing the validation algorithm
#print(predictor)
#print("End of first output of predictor")
predictionVariable <- input$theVariable
#outputType <- "categorical"
}
else if(input$theDataSet == 'Marketing')
{
dataset <- read.csv("marketing.csv")
predictor <- dataset$sales
predictionVariable <- input$theVariable
#outputType <- "continuous"
}
else if(input$theDataSet == "Heart Disease")
{
#https://www.youtube.com/watch?v=C4N3_XJJ-jU was important
dataset <- read.csv("HeartDiseaseData.csv")
#Cleaning
dataset[dataset == "?"] <- NA
dataset <- na.omit(dataset)
dataset[dataset$sex == 0,]$sex <- "female"
dataset[dataset$sex == 1,]$sex <- "male"
dataset$sex <- as.factor(dataset$sex)
dataset$cp <- as.factor(dataset$cp)
dataset$fbs <- as.factor(dataset$fbs)
dataset$restecg <- as.factor(dataset$restecg)
dataset$exang <- as.factor(dataset$exang)
dataset$slope <- as.factor(dataset$slope)
dataset$ca <- as.integer(dataset$ca)
dataset$ca <- as.factor(dataset$ca)
dataset$thal <- as.integer(dataset$thal) # "thal" also had "?"s in it.
dataset$thal <- as.factor(dataset$thal)
## This next line replaces 0 and 1 with "Healthy" and "Unhealthy"
#dataset$target <- ifelse(test=dataset$target == 0, yes="Healthy", no="Unhealthy") #I might remove
dataset$target <- as.factor(dataset$target) # Now convert to a factor
predictor <- dataset$target
predictionVariable <- input$theVariable
}
else if(input$theDataSet == 'Palmer Penguins'){
dataset <- na.omit(penguins)
predictor <- dataset$species
predictionVariable <- input$theVariable
#outputType <- "categorical"
}
else if(input$theDataSet == "House Data"){
dataset <- read.csv("HouseTrain.csv")
predictor <- dataset$SalePrice
predictionVariable <- input$theVariable
#outputType <- "categorical"
}
else{
print('ERROR')
}
trainingPercents <-.5
count <- 1
testingPercent <- list(.5,.55,.6,.65,.7,.75,.8,.85,.9,.95)
newAverages <- list(0,0,0,0,0,0,0,0,0,0)
totalRuns <- as.numeric(input$repetitions)
count <- 1
#As the probability is being calculated these lists store the values from each test and sort them by percent in training data
#  so for instance consistency70 is 70% training data and 30% validation data
consistency50 <- vector(mode = "list", length = totalRuns)
consistency55 <- vector(mode = "list", length = totalRuns)
consistency60 <- vector(mode = "list", length = totalRuns)
consistency65 <- vector(mode = "list", length = totalRuns)
consistency70 <- vector(mode = "list", length = totalRuns)
consistency75 <- vector(mode = "list", length = totalRuns)
consistency80 <- vector(mode = "list", length = totalRuns)
consistency85 <- vector(mode = "list", length = totalRuns)
consistency90 <- vector(mode = "list", length = totalRuns)
consistency95 <- vector(mode = "list", length = totalRuns)
count <- 1
#Each run calculates 1 accuracy for each of the 10 training prportions
#  It runs as many times as totalRuns
while(count <= totalRuns)
{
percentCorrectCalculation <- lapply(X = testingPercent, FUN = calculateAccuracy, theDataSet = dataset, method = input$theMethod, predictor = predictor, predictionVariable = predictionVariable) #Ethan
consistency50[count] <- percentCorrectCalculation[[1]]
consistency55[count] <- percentCorrectCalculation[[2]]
consistency60[count] <- percentCorrectCalculation[[3]]
consistency65[count] <- percentCorrectCalculation[[4]]
consistency70[count] <- percentCorrectCalculation[[5]]
consistency75[count] <- percentCorrectCalculation[[6]]
consistency80[count] <- percentCorrectCalculation[[7]]
consistency85[count] <- percentCorrectCalculation[[8]]
consistency90[count] <- percentCorrectCalculation[[9]]
consistency95[count] <- percentCorrectCalculation[[10]]
newAverages <- list(newAverages[[1]] + percentCorrectCalculation[[1]], newAverages[[2]] + percentCorrectCalculation[[2]], newAverages[[3]] + percentCorrectCalculation[[3]],
newAverages[[4]] + percentCorrectCalculation[[4]], newAverages[[5]] + percentCorrectCalculation[[5]], newAverages[[6]] + percentCorrectCalculation[[6]],
newAverages[[7]] + percentCorrectCalculation[[7]], newAverages[[8]] + percentCorrectCalculation[[8]], newAverages[[9]] + percentCorrectCalculation[[9]],
newAverages[[10]] + percentCorrectCalculation[[10]])
count <- count + 1
}
percentCorrectCalculation <- list(newAverages[[1]] / totalRuns, newAverages[[2]] / totalRuns, newAverages[[3]] / totalRuns,
newAverages[[4]] / totalRuns, newAverages[[5]] / totalRuns, newAverages[[6]] / totalRuns,
newAverages[[7]] / totalRuns, newAverages[[8]] / totalRuns, newAverages[[9]] / totalRuns,
newAverages[[10]] / totalRuns)
#######Section to Calculate standard deviation
#Used to contain these inside the 2 different if else below but don't beleive that is necessary
stdev = list(0, 0, 0, 0, 0, 0, 0, 0, 0, 0)
#The size of each consistency## is equal to the size of the totalRuns
stdev[[1]] <- sd(unlist(x = consistency50, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
stdev[[2]] <- sd(unlist(x = consistency55, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
stdev[[3]] <- sd(unlist(x = consistency60, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
stdev[[4]] <- sd(unlist(x = consistency65, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
stdev[[5]] <- sd(unlist(x = consistency70, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
stdev[[6]] <- sd(unlist(x = consistency75, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
stdev[[7]] <- sd(unlist(x = consistency80, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
stdev[[8]] <- sd(unlist(x = consistency85, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
stdev[[9]] <- sd(unlist(x = consistency90, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
stdev[[10]] <- sd(unlist(x = consistency95, recursive = TRUE, use.names = TRUE), na.rm = TRUE)
#Output the plots
#Categorical
if(input$theMethod == "Linear Discriminant Analysis" || input$theMethod == "Logistic Regression")
{
accuracyDataFrame <- do.call(rbind, Map(data.frame, testingPercent = testingPercent, percentCorrectCalculation = percentCorrectCalculation))
output$overallPlot <- renderPlot({ggplot(data = accuracyDataFrame, aes(testingPercent * 100, percentCorrectCalculation)) +
xlab("Percent In Training Set") +
ylab("Percent Correct") +
theme(text = element_text(size=20)) +
geom_point(alpha = 0.25) +
stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1, se = FALSE)
})
resultsDataFrame <- do.call(rbind, Map(data.frame, testingPercent = testingPercent, stdev = stdev))
output$consistencyPlot <- renderPlot({ggplot(data = resultsDataFrame, aes(testingPercent * 100, stdev)) +
xlab("Percent In Training Set") +
ylab("Standard deviation of Percent Correct") +
theme(text = element_text(size=20)) +
geom_point(alpha = 0.25) +
stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1, se = FALSE)
})
}
else #quantitative
{
accuracyDataFrame <- do.call(rbind, Map(data.frame, testingPercent = testingPercent, percentCorrectCalculation = percentCorrectCalculation))
output$overallPlot <- renderPlot({ggplot(data = accuracyDataFrame, aes(testingPercent * 100, percentCorrectCalculation)) +
xlab("Percent In Training Set") +
ylab("MSE of the Distance From True Answer") +
theme(text = element_text(size=20)) +
geom_point(alpha = 0.25) +
stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1, se = FALSE)
})
#STD deviation
resultsDataFrame <- do.call(rbind, Map(data.frame, testingPercent = testingPercent, stdev = stdev))
output$consistencyPlot <- renderPlot({ggplot(data = resultsDataFrame, aes(testingPercent * 100, stdev)) +
xlab("Percent In Training Set") +
ylab("St Dev of the absolute distance") +
geom_point() +
theme(text = element_text(size=20)) +
stat_smooth(method = "lm", formula = y ~ poly(x, 3), size = 1, se = FALSE)
#+ lines(aes(testingPercent, predict(quadraticRegression), col = 2))
})
}
})
#----observeEvent(input$newGraphOutput)----
observeEvent(input$newGraphOutput, {
if(input$theDataSet == 'Iris'){
dataset <- na.omit(iris)
#predictor is the variable that we are going to try to predict
predictor <- iris$Species
predictionVariable <- input$theVariable
#outputType <- "categorical"
}
else if(input$theDataSet == 'Marketing')
{
dataset <- read.csv("marketing.csv")
predictor <- dataset$sales
predictionVariable <- input$theVariable
#outputType <- "continuous"
}
else if(input$theDataSet == "Heart Disease")
{
#https://www.youtube.com/watch?v=C4N3_XJJ-jU was important
dataset <- read.csv("HeartDiseaseData.csv")
#Cleaning
dataset[dataset == "?"] <- NA
dataset <- na.omit(dataset)
#test
dataset[dataset$sex == 0,]$sex <- "female"
dataset[dataset$sex == 1,]$sex <- "male"
dataset$sex <- as.factor(dataset$sex)
dataset$fbs <- as.factor(dataset$fbs)
dataset$exang <- as.factor(dataset$exang)
dataset$ca <- as.integer(dataset$ca)
dataset$thal <- as.integer(dataset$thal) # "thal" also had "?"s in it.
## This next line replaces 0 and 1 with "Healthy" and "Unhealthy"
#dataset$target <- ifelse(test=dataset$target == 0, yes="Healthy", no="Unhealthy") #I might remove
dataset$target <- as.factor(dataset$target) # Now convert to a factor
predictor <- dataset$target
predictionVariable <- input$theVariable
}
else if(input$theDataSet == 'Palmer Penguins'){
dataset <- na.omit(penguins)
predictor <- dataset$species
predictionVariable <- input$theVariable
#outputType <- "categorical"
}
else if(input$theDataSet == "House Data"){
dataset <- read.csv("HouseTrain.csv")
predictor <- dataset$SalePrice
predictionVariable <- input$theVariable
#outputType <- "categorical"
}
else{
print('ERROR')
}
#consistency50 <- vector(mode = "list", length = totalRuns)
count <- 1
totalRuns <- as.numeric(input$repetitions)
while(count <= totalRuns)
{
percentCorrect <- calculateAccuracy(dataset, input$testingPercent, input$theMethod, predictor, predictionVariable)
percentCorrect <- signif(percentCorrect,4)
currentPoints <- data.frame(
percentTraining = input$testingPercent,
accuracyValue = percentCorrect
)
count <- count+1
###---- Store new values ----
tracking$DT <- rbind(tracking$DT, currentPoints)
}
})
basePerformPlot <- ggplot(
data = data.frame(x = seq(from = 0.2, to = 1), y = seq(from = 0, to = 1)),
mapping = aes(x = x, y = y)
) +
theme_bw() +
xlab("Proportion in Training Set") +
ylab("MSE error") +
labs(title = "The Accuracy of Every Test") +
theme(
text = element_text(size = 18)
) +
scale_x_continuous(limits = c(.2, 1), expand = expansion(mult = 0.01, add = 0)) +
scale_y_continuous(limits = c(100, 550), expand = expansion(mult = 0.01, add = 0), labels = scaleFUN)
output$variancePlot <- renderPlot({
basePerformPlot +
scale_y_continuous(limits = c(minYAxis(), maxYAxis(), expand = expansion(mult = 0.01, add = 0)), labels = scaleFUN) +
geom_point(
data = tracking$DT,
alpha = 0.33,
mapping = aes(
x = percentTraining,
y = accuracyValue
),
size = 4
) +
ylab(yLabel()) +
theme(
legend.position = "bottom"
)
#geom_errorbar(stat="summary", fun.data="mean_se", fun.args = list(mult = 1.96))
})
output$AccuracyPlot <- renderPlot({
#Compute the average of the points at each location X
subset20 <- mean(subset(tracking$DT, (percentTraining == .2))$accuracyValue)
subset25 <- mean(subset(tracking$DT, (percentTraining == .25))$accuracyValue)
subset30 <- mean(subset(tracking$DT, (percentTraining == .3))$accuracyValue)
subset35 <- mean(subset(tracking$DT, (percentTraining == .35))$accuracyValue)
subset40 <- mean(subset(tracking$DT, (percentTraining == .4))$accuracyValue)
subset45 <- mean(subset(tracking$DT, (percentTraining == .45))$accuracyValue)
subset50 <- mean(subset(tracking$DT, (percentTraining == .5))$accuracyValue)
subset55 <- mean(subset(tracking$DT, (percentTraining == .55))$accuracyValue)
subset60 <- mean(subset(tracking$DT, (percentTraining == .6))$accuracyValue)
subset65 <- mean(subset(tracking$DT, (percentTraining == .65))$accuracyValue)
subset70 <- mean(subset(tracking$DT, (percentTraining == .7))$accuracyValue)
subset75 <- mean(subset(tracking$DT, (percentTraining == .75))$accuracyValue)
subset80 <- mean(subset(tracking$DT, (percentTraining == .8))$accuracyValue)
subset85 <- mean(subset(tracking$DT, (percentTraining == .85))$accuracyValue)
subset90 <- mean(subset(tracking$DT, (percentTraining == .9))$accuracyValue)
subset95 <- mean(subset(tracking$DT, (percentTraining == .95))$accuracyValue)
#Put these values into a list along with their corresponding percents in a parellel vector
averagesList <- c(subset20, subset25, subset30, subset35, subset40, subset45,
subset50, subset55, subset60, subset65, subset70, subset75,
subset80, subset85, subset90, subset95)
percents <- c(.2, .25, .3, .35, .4, .45, .5, .55, .6, .65, .7, .75, .8, .85, .9, .95)
meanPoints <- data.frame(averagesList, percents)
meanPoints <- subset(meanPoints, (averagesList != 'NaN'))
ggplot(data = meanPoints, aes(x = percents, y = averagesList)) +
geom_point(
data = meanPoints,
mapping = aes(
x = percents,
y = averagesList
),
size = 4
) +
theme_bw() +
theme(
text = element_text(size = 18),
) +
xlab("Proportion in Training Set") +
ylab(paste('Mean of the', yLabel())) +
labs(title = "Mean Accuracy") +
stat_smooth(method = "lm", formula = y ~ poly(x, 1), size = 1, se = FALSE) +
scale_y_continuous(limits = c(meanMinYAxis(), meanMaxYAxis(), expand = expansion(mult = 0.01, add = 0)), labels = scaleFUN) +
scale_x_continuous(limits = c(.2, 1))
})
}
#shinyApp(ui = ui, server = server)
boastUtils::boastApp(ui = ui, server = server)
runApp('GitHub/Machine-Learning-Training-vs-Validation/Backup App (being updated).R')
runApp('GitHub/Validation_vs_Testing_Dataset_App')
runApp('GitHub/Validation_vs_Testing_Dataset_App')
runApp('GitHub/Machine-Learning-Training-vs-Validation/Backup App (being updated).R')
read.dcf()
setwd("~/GitHub/Validation_vs_Testing_Dataset_App")
read.dcf("DESCRIPTION")
runApp('~/GitHub/Machine-Learning-Training-vs-Validation/Backup App (being updated).R')
runApp('~/GitHub/Machine-Learning-Training-vs-Validation/Backup App (being updated).R')
runApp()
runApp()
runApp()
runApp('~/GitHub/Machine-Learning-Training-vs-Validation/Backup App (being updated).R')
runApp('~/GitHub/Machine-Learning-Training-vs-Validation/Backup App (being updated).R')
runApp('~/GitHub/Machine-Learning-Training-vs-Validation/Backup App (being updated).R')
runApp('~/GitHub/Machine-Learning-Training-vs-Validation/Backup App (being updated).R')
runApp('~/GitHub/Machine-Learning-Training-vs-Validation/Backup App (being updated).R')
